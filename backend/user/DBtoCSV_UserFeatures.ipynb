{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# environment setup\n",
    "import sys\n",
    "sys.path.append('../../Data')\n",
    "sys.path.append('../..')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "  %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_api import *\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "from backend.user.utils import *\n",
    "from backend.user.calculation import *\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import ast\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_features_to_csv(output_file):\n",
    "    \"\"\"\n",
    "    Write all the features of users into a csv file\n",
    "    :param conn: the connection to the database\n",
    "    :param output_file: the output file name\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    database = database_api('/Users/ziandong/TreeMusicRecommendation/Data/conf.json')\n",
    "    users = database.get_all_users()\n",
    "    user_ids = [user[0] for user in users] \n",
    "\n",
    "\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['user_id', 'Top Tracks', 'Top Artists', 'Top Tags']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        i = 0\n",
    "        while i < len(user_ids):\n",
    "            try:\n",
    "                print(\"Fetching data for user \" + str(i))\n",
    "                user_id = user_ids[i]\n",
    "                features = database.get_user_features(user_id)\n",
    "\n",
    "                # Get the feature information\n",
    "                top_tracks = features['top_tracks']\n",
    "                top_artists = features['top_artists']\n",
    "\n",
    "\n",
    "\n",
    "                # Convert the feature information into feature scores\n",
    "                top_tracks_score = calculate_top_tracks_score(top_tracks)\n",
    "                top_artists_score = calculate_top_artists_score(top_artists)\n",
    "                top_tags = fetch_user_tag(urls_to_text(list(top_artists.keys())[0:10]))\n",
    "\n",
    "\n",
    "\n",
    "                # Convert the feature scores into the JSON format\n",
    "                json_top_tracks_score = json.dumps(top_tracks_score)\n",
    "                json_top_artists_score = json.dumps(top_artists_score)\n",
    "                json_top_tags = json.dumps(top_tags)\n",
    "\n",
    "                writer.writerow({\n",
    "                    'user_id': user_id,\n",
    "                    'Top Tracks': json_top_tracks_score,\n",
    "                    'Top Artists': json_top_artists_score,\n",
    "                    'Top Tags': json_top_tags\n",
    "                })\n",
    "                i += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Error: unable to fetch data for user \" + str(user_id))\n",
    "                writer.writerow({\n",
    "                    'user_id': user_id,\n",
    "                    'Top Tracks': None,\n",
    "                    'Top Artists': None,\n",
    "                    'Top Tags': None\n",
    "                })\n",
    "                i += 1\n",
    "                continue\n",
    "    database.close_connection()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'database_api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m write_features_to_csv(\u001b[39m'\u001b[39;49m\u001b[39muser_features.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb Cell 8\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_features_to_csv\u001b[39m(output_file):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    Write all the features of users into a csv file\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    :param conn: the connection to the database\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    :param output_file: the output file name\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m    :return: None\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     database \u001b[39m=\u001b[39m database_api(\u001b[39m'\u001b[39m\u001b[39m/Users/ziandong/TreeMusicRecommendation/Data/conf.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     users \u001b[39m=\u001b[39m database\u001b[39m.\u001b[39mget_all_users()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ziandong/TreeMusicRecommendation/backend/user/DBtoCSV_UserFeatures.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     user_ids \u001b[39m=\u001b[39m [user[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m user \u001b[39min\u001b[39;00m users] \n",
      "\u001b[0;31mNameError\u001b[0m: name 'database_api' is not defined"
     ]
    }
   ],
   "source": [
    "write_features_to_csv('user_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for user 0\n"
     ]
    }
   ],
   "source": [
    "write_features_to_csv('user_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_csv(all_feature_csv, feature, chunk_size=100, length = 10):\n",
    "    df = pd.read_csv(all_feature_csv)\n",
    "    df = df.dropna()\n",
    "\n",
    "    if feature == \"Top Tags\":\n",
    "        df[feature] = df[feature].apply(lambda x: x.split(', '))\n",
    "        df[feature] = df[feature].apply(lambda x: {tag.split(\": \")[0].replace('\"', ''): float(tag.split(\": \")[1].replace('\"', '')) for tag in x})       \n",
    "    else:    \n",
    "        df[feature] = df[feature].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "    # Process the data in chunks\n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        print(f\"Processing chunk {i} to {i+chunk_size}...\")\n",
    "        chunk = df.iloc[i:i+chunk_size]\n",
    "        chunk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Create a list of dictionaries\n",
    "        data = []\n",
    "        for idx, row in chunk.iterrows():\n",
    "\n",
    "            top_10_dict = {key: row[feature][key] for key in list(row[feature].keys())[0:length]}\n",
    "            data.append(top_10_dict)\n",
    "\n",
    "\n",
    "        # Convert the list into a DataFrame\n",
    "        df_chunk = pd.DataFrame(data)\n",
    "\n",
    "        # Add the user_id column\n",
    "        df_chunk[\"user_id\"] = chunk[\"user_id\"]\n",
    "\n",
    "        directory = \"user_features\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Save this chunk to a CSV file\n",
    "        print(f\"Saving chunk {i} to a CSV file...\")\n",
    "        chunk_csv_path = f\"{directory}/{feature}_{i}.csv\"\n",
    "        df_chunk.to_csv(chunk_csv_path, index=False)\n",
    "\n",
    "def concatenate_feature_csvs(feature):\n",
    "    directory = \"user_features\"\n",
    "    csv_files = [f\"{directory}/{file}\" for file in os.listdir(directory) if file.startswith(feature)]\n",
    "\n",
    "\n",
    "    dfs= []\n",
    "    for i in range(len(csv_files)):\n",
    "        df = pd.read_csv(csv_files[i])\n",
    "        dfs.append(df)\n",
    "\n",
    "        \n",
    "    # Concatenate all the CSV files into a single DataFrame\n",
    "    print(\"concatenating...\")\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(\"finished concatenating\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 0 to 100...\n",
      "Saving chunk 0 to a CSV file...\n",
      "Processing chunk 100 to 200...\n",
      "Saving chunk 100 to a CSV file...\n",
      "Processing chunk 200 to 300...\n",
      "Saving chunk 200 to a CSV file...\n",
      "Processing chunk 300 to 400...\n",
      "Saving chunk 300 to a CSV file...\n",
      "Processing chunk 400 to 500...\n",
      "Saving chunk 400 to a CSV file...\n",
      "Processing chunk 500 to 600...\n",
      "Saving chunk 500 to a CSV file...\n",
      "Processing chunk 600 to 700...\n",
      "Saving chunk 600 to a CSV file...\n",
      "Processing chunk 700 to 800...\n",
      "Saving chunk 700 to a CSV file...\n",
      "Processing chunk 800 to 900...\n",
      "Saving chunk 800 to a CSV file...\n",
      "Processing chunk 900 to 1000...\n",
      "Saving chunk 900 to a CSV file...\n",
      "Processing chunk 1000 to 1100...\n",
      "Saving chunk 1000 to a CSV file...\n",
      "Processing chunk 1100 to 1200...\n",
      "Saving chunk 1100 to a CSV file...\n",
      "Processing chunk 1200 to 1300...\n",
      "Saving chunk 1200 to a CSV file...\n",
      "Processing chunk 1300 to 1400...\n",
      "Saving chunk 1300 to a CSV file...\n",
      "Processing chunk 1400 to 1500...\n",
      "Saving chunk 1400 to a CSV file...\n",
      "Processing chunk 1500 to 1600...\n",
      "Saving chunk 1500 to a CSV file...\n",
      "Processing chunk 1600 to 1700...\n",
      "Saving chunk 1600 to a CSV file...\n",
      "Processing chunk 1700 to 1800...\n",
      "Saving chunk 1700 to a CSV file...\n",
      "Processing chunk 1800 to 1900...\n",
      "Saving chunk 1800 to a CSV file...\n",
      "Processing chunk 1900 to 2000...\n",
      "Saving chunk 1900 to a CSV file...\n",
      "Processing chunk 2000 to 2100...\n",
      "Saving chunk 2000 to a CSV file...\n",
      "Processing chunk 2100 to 2200...\n",
      "Saving chunk 2100 to a CSV file...\n",
      "Processing chunk 2200 to 2300...\n",
      "Saving chunk 2200 to a CSV file...\n",
      "Processing chunk 2300 to 2400...\n",
      "Saving chunk 2300 to a CSV file...\n",
      "Processing chunk 2400 to 2500...\n",
      "Saving chunk 2400 to a CSV file...\n",
      "Processing chunk 2500 to 2600...\n",
      "Saving chunk 2500 to a CSV file...\n",
      "Processing chunk 2600 to 2700...\n",
      "Saving chunk 2600 to a CSV file...\n",
      "Processing chunk 2700 to 2800...\n",
      "Saving chunk 2700 to a CSV file...\n",
      "Processing chunk 2800 to 2900...\n",
      "Saving chunk 2800 to a CSV file...\n",
      "Processing chunk 2900 to 3000...\n",
      "Saving chunk 2900 to a CSV file...\n",
      "Processing chunk 3000 to 3100...\n",
      "Saving chunk 3000 to a CSV file...\n",
      "Processing chunk 3100 to 3200...\n",
      "Saving chunk 3100 to a CSV file...\n",
      "Processing chunk 3200 to 3300...\n",
      "Saving chunk 3200 to a CSV file...\n",
      "Processing chunk 3300 to 3400...\n",
      "Saving chunk 3300 to a CSV file...\n",
      "Processing chunk 3400 to 3500...\n",
      "Saving chunk 3400 to a CSV file...\n",
      "Processing chunk 3500 to 3600...\n",
      "Saving chunk 3500 to a CSV file...\n",
      "Processing chunk 3600 to 3700...\n",
      "Saving chunk 3600 to a CSV file...\n",
      "Processing chunk 3700 to 3800...\n",
      "Saving chunk 3700 to a CSV file...\n",
      "Processing chunk 3800 to 3900...\n",
      "Saving chunk 3800 to a CSV file...\n",
      "Processing chunk 3900 to 4000...\n",
      "Saving chunk 3900 to a CSV file...\n",
      "Processing chunk 4000 to 4100...\n",
      "Saving chunk 4000 to a CSV file...\n",
      "Processing chunk 4100 to 4200...\n",
      "Saving chunk 4100 to a CSV file...\n",
      "Processing chunk 4200 to 4300...\n",
      "Saving chunk 4200 to a CSV file...\n",
      "Processing chunk 4300 to 4400...\n",
      "Saving chunk 4300 to a CSV file...\n",
      "Processing chunk 4400 to 4500...\n",
      "Saving chunk 4400 to a CSV file...\n",
      "Processing chunk 4500 to 4600...\n",
      "Saving chunk 4500 to a CSV file...\n",
      "Processing chunk 4600 to 4700...\n",
      "Saving chunk 4600 to a CSV file...\n",
      "Processing chunk 4700 to 4800...\n",
      "Saving chunk 4700 to a CSV file...\n",
      "Processing chunk 4800 to 4900...\n",
      "Saving chunk 4800 to a CSV file...\n",
      "Processing chunk 4900 to 5000...\n",
      "Saving chunk 4900 to a CSV file...\n",
      "Processing chunk 5000 to 5100...\n",
      "Saving chunk 5000 to a CSV file...\n",
      "Processing chunk 5100 to 5200...\n",
      "Saving chunk 5100 to a CSV file...\n",
      "Processing chunk 5200 to 5300...\n",
      "Saving chunk 5200 to a CSV file...\n",
      "Processing chunk 5300 to 5400...\n",
      "Saving chunk 5300 to a CSV file...\n",
      "Processing chunk 5400 to 5500...\n",
      "Saving chunk 5400 to a CSV file...\n",
      "Processing chunk 5500 to 5600...\n",
      "Saving chunk 5500 to a CSV file...\n",
      "Processing chunk 5600 to 5700...\n",
      "Saving chunk 5600 to a CSV file...\n",
      "Processing chunk 5700 to 5800...\n",
      "Saving chunk 5700 to a CSV file...\n",
      "Processing chunk 5800 to 5900...\n",
      "Saving chunk 5800 to a CSV file...\n",
      "Processing chunk 5900 to 6000...\n",
      "Saving chunk 5900 to a CSV file...\n",
      "Processing chunk 6000 to 6100...\n",
      "Saving chunk 6000 to a CSV file...\n",
      "Processing chunk 6100 to 6200...\n",
      "Saving chunk 6100 to a CSV file...\n",
      "Processing chunk 6200 to 6300...\n",
      "Saving chunk 6200 to a CSV file...\n",
      "Processing chunk 6300 to 6400...\n",
      "Saving chunk 6300 to a CSV file...\n",
      "Processing chunk 6400 to 6500...\n",
      "Saving chunk 6400 to a CSV file...\n",
      "Processing chunk 6500 to 6600...\n",
      "Saving chunk 6500 to a CSV file...\n",
      "Processing chunk 6600 to 6700...\n",
      "Saving chunk 6600 to a CSV file...\n",
      "Processing chunk 6700 to 6800...\n",
      "Saving chunk 6700 to a CSV file...\n",
      "Processing chunk 6800 to 6900...\n",
      "Saving chunk 6800 to a CSV file...\n",
      "Processing chunk 6900 to 7000...\n",
      "Saving chunk 6900 to a CSV file...\n",
      "Processing chunk 7000 to 7100...\n",
      "Saving chunk 7000 to a CSV file...\n",
      "Processing chunk 7100 to 7200...\n",
      "Saving chunk 7100 to a CSV file...\n",
      "Processing chunk 7200 to 7300...\n",
      "Saving chunk 7200 to a CSV file...\n",
      "Processing chunk 7300 to 7400...\n",
      "Saving chunk 7300 to a CSV file...\n",
      "Processing chunk 7400 to 7500...\n",
      "Saving chunk 7400 to a CSV file...\n",
      "Processing chunk 7500 to 7600...\n",
      "Saving chunk 7500 to a CSV file...\n",
      "Processing chunk 7600 to 7700...\n",
      "Saving chunk 7600 to a CSV file...\n",
      "Processing chunk 7700 to 7800...\n",
      "Saving chunk 7700 to a CSV file...\n",
      "Processing chunk 7800 to 7900...\n",
      "Saving chunk 7800 to a CSV file...\n",
      "Processing chunk 7900 to 8000...\n",
      "Saving chunk 7900 to a CSV file...\n",
      "Processing chunk 8000 to 8100...\n",
      "Saving chunk 8000 to a CSV file...\n",
      "Processing chunk 8100 to 8200...\n",
      "Saving chunk 8100 to a CSV file...\n",
      "Processing chunk 8200 to 8300...\n",
      "Saving chunk 8200 to a CSV file...\n",
      "Processing chunk 8300 to 8400...\n",
      "Saving chunk 8300 to a CSV file...\n",
      "Processing chunk 8400 to 8500...\n",
      "Saving chunk 8400 to a CSV file...\n"
     ]
    }
   ],
   "source": [
    "feature_csv(\"user_features.csv\", \"Top Tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 0 to 100...\n",
      "Saving chunk 0 to a CSV file...\n",
      "Processing chunk 100 to 200...\n",
      "Saving chunk 100 to a CSV file...\n",
      "Processing chunk 200 to 300...\n",
      "Saving chunk 200 to a CSV file...\n",
      "Processing chunk 300 to 400...\n",
      "Saving chunk 300 to a CSV file...\n",
      "Processing chunk 400 to 500...\n",
      "Saving chunk 400 to a CSV file...\n",
      "Processing chunk 500 to 600...\n",
      "Saving chunk 500 to a CSV file...\n",
      "Processing chunk 600 to 700...\n",
      "Saving chunk 600 to a CSV file...\n",
      "Processing chunk 700 to 800...\n",
      "Saving chunk 700 to a CSV file...\n",
      "Processing chunk 800 to 900...\n",
      "Saving chunk 800 to a CSV file...\n",
      "Processing chunk 900 to 1000...\n",
      "Saving chunk 900 to a CSV file...\n",
      "Processing chunk 1000 to 1100...\n",
      "Saving chunk 1000 to a CSV file...\n",
      "Processing chunk 1100 to 1200...\n",
      "Saving chunk 1100 to a CSV file...\n",
      "Processing chunk 1200 to 1300...\n",
      "Saving chunk 1200 to a CSV file...\n",
      "Processing chunk 1300 to 1400...\n",
      "Saving chunk 1300 to a CSV file...\n",
      "Processing chunk 1400 to 1500...\n",
      "Saving chunk 1400 to a CSV file...\n",
      "Processing chunk 1500 to 1600...\n",
      "Saving chunk 1500 to a CSV file...\n",
      "Processing chunk 1600 to 1700...\n",
      "Saving chunk 1600 to a CSV file...\n",
      "Processing chunk 1700 to 1800...\n",
      "Saving chunk 1700 to a CSV file...\n",
      "Processing chunk 1800 to 1900...\n",
      "Saving chunk 1800 to a CSV file...\n",
      "Processing chunk 1900 to 2000...\n",
      "Saving chunk 1900 to a CSV file...\n",
      "Processing chunk 2000 to 2100...\n",
      "Saving chunk 2000 to a CSV file...\n",
      "Processing chunk 2100 to 2200...\n",
      "Saving chunk 2100 to a CSV file...\n",
      "Processing chunk 2200 to 2300...\n",
      "Saving chunk 2200 to a CSV file...\n",
      "Processing chunk 2300 to 2400...\n",
      "Saving chunk 2300 to a CSV file...\n",
      "Processing chunk 2400 to 2500...\n",
      "Saving chunk 2400 to a CSV file...\n",
      "Processing chunk 2500 to 2600...\n",
      "Saving chunk 2500 to a CSV file...\n",
      "Processing chunk 2600 to 2700...\n",
      "Saving chunk 2600 to a CSV file...\n",
      "Processing chunk 2700 to 2800...\n",
      "Saving chunk 2700 to a CSV file...\n",
      "Processing chunk 2800 to 2900...\n",
      "Saving chunk 2800 to a CSV file...\n",
      "Processing chunk 2900 to 3000...\n",
      "Saving chunk 2900 to a CSV file...\n",
      "Processing chunk 3000 to 3100...\n",
      "Saving chunk 3000 to a CSV file...\n",
      "Processing chunk 3100 to 3200...\n",
      "Saving chunk 3100 to a CSV file...\n",
      "Processing chunk 3200 to 3300...\n",
      "Saving chunk 3200 to a CSV file...\n",
      "Processing chunk 3300 to 3400...\n",
      "Saving chunk 3300 to a CSV file...\n",
      "Processing chunk 3400 to 3500...\n",
      "Saving chunk 3400 to a CSV file...\n",
      "Processing chunk 3500 to 3600...\n",
      "Saving chunk 3500 to a CSV file...\n",
      "Processing chunk 3600 to 3700...\n",
      "Saving chunk 3600 to a CSV file...\n",
      "Processing chunk 3700 to 3800...\n",
      "Saving chunk 3700 to a CSV file...\n",
      "Processing chunk 3800 to 3900...\n",
      "Saving chunk 3800 to a CSV file...\n",
      "Processing chunk 3900 to 4000...\n",
      "Saving chunk 3900 to a CSV file...\n",
      "Processing chunk 4000 to 4100...\n",
      "Saving chunk 4000 to a CSV file...\n",
      "Processing chunk 4100 to 4200...\n",
      "Saving chunk 4100 to a CSV file...\n",
      "Processing chunk 4200 to 4300...\n",
      "Saving chunk 4200 to a CSV file...\n",
      "Processing chunk 4300 to 4400...\n",
      "Saving chunk 4300 to a CSV file...\n",
      "Processing chunk 4400 to 4500...\n",
      "Saving chunk 4400 to a CSV file...\n",
      "Processing chunk 4500 to 4600...\n",
      "Saving chunk 4500 to a CSV file...\n",
      "Processing chunk 4600 to 4700...\n",
      "Saving chunk 4600 to a CSV file...\n",
      "Processing chunk 4700 to 4800...\n",
      "Saving chunk 4700 to a CSV file...\n",
      "Processing chunk 4800 to 4900...\n",
      "Saving chunk 4800 to a CSV file...\n",
      "Processing chunk 4900 to 5000...\n",
      "Saving chunk 4900 to a CSV file...\n",
      "Processing chunk 5000 to 5100...\n",
      "Saving chunk 5000 to a CSV file...\n",
      "Processing chunk 5100 to 5200...\n",
      "Saving chunk 5100 to a CSV file...\n",
      "Processing chunk 5200 to 5300...\n",
      "Saving chunk 5200 to a CSV file...\n",
      "Processing chunk 5300 to 5400...\n",
      "Saving chunk 5300 to a CSV file...\n",
      "Processing chunk 5400 to 5500...\n",
      "Saving chunk 5400 to a CSV file...\n",
      "Processing chunk 5500 to 5600...\n",
      "Saving chunk 5500 to a CSV file...\n",
      "Processing chunk 5600 to 5700...\n",
      "Saving chunk 5600 to a CSV file...\n",
      "Processing chunk 5700 to 5800...\n",
      "Saving chunk 5700 to a CSV file...\n",
      "Processing chunk 5800 to 5900...\n",
      "Saving chunk 5800 to a CSV file...\n",
      "Processing chunk 5900 to 6000...\n",
      "Saving chunk 5900 to a CSV file...\n",
      "Processing chunk 6000 to 6100...\n",
      "Saving chunk 6000 to a CSV file...\n",
      "Processing chunk 6100 to 6200...\n",
      "Saving chunk 6100 to a CSV file...\n",
      "Processing chunk 6200 to 6300...\n",
      "Saving chunk 6200 to a CSV file...\n",
      "Processing chunk 6300 to 6400...\n",
      "Saving chunk 6300 to a CSV file...\n",
      "Processing chunk 6400 to 6500...\n",
      "Saving chunk 6400 to a CSV file...\n",
      "Processing chunk 6500 to 6600...\n",
      "Saving chunk 6500 to a CSV file...\n",
      "Processing chunk 6600 to 6700...\n",
      "Saving chunk 6600 to a CSV file...\n",
      "Processing chunk 6700 to 6800...\n",
      "Saving chunk 6700 to a CSV file...\n",
      "Processing chunk 6800 to 6900...\n",
      "Saving chunk 6800 to a CSV file...\n",
      "Processing chunk 6900 to 7000...\n",
      "Saving chunk 6900 to a CSV file...\n",
      "Processing chunk 7000 to 7100...\n",
      "Saving chunk 7000 to a CSV file...\n",
      "Processing chunk 7100 to 7200...\n",
      "Saving chunk 7100 to a CSV file...\n",
      "Processing chunk 7200 to 7300...\n",
      "Saving chunk 7200 to a CSV file...\n",
      "Processing chunk 7300 to 7400...\n",
      "Saving chunk 7300 to a CSV file...\n",
      "Processing chunk 7400 to 7500...\n",
      "Saving chunk 7400 to a CSV file...\n",
      "Processing chunk 7500 to 7600...\n",
      "Saving chunk 7500 to a CSV file...\n",
      "Processing chunk 7600 to 7700...\n",
      "Saving chunk 7600 to a CSV file...\n",
      "Processing chunk 7700 to 7800...\n",
      "Saving chunk 7700 to a CSV file...\n",
      "Processing chunk 7800 to 7900...\n",
      "Saving chunk 7800 to a CSV file...\n",
      "Processing chunk 7900 to 8000...\n",
      "Saving chunk 7900 to a CSV file...\n",
      "Processing chunk 8000 to 8100...\n",
      "Saving chunk 8000 to a CSV file...\n",
      "Processing chunk 8100 to 8200...\n",
      "Saving chunk 8100 to a CSV file...\n",
      "Processing chunk 8200 to 8300...\n",
      "Saving chunk 8200 to a CSV file...\n",
      "Processing chunk 8300 to 8400...\n",
      "Saving chunk 8300 to a CSV file...\n",
      "Processing chunk 8400 to 8500...\n",
      "Saving chunk 8400 to a CSV file...\n"
     ]
    }
   ],
   "source": [
    "feature_csv(\"user_features.csv\", \"Top Artists\", chunk_size=100, length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 0 to 100...\n",
      "Saving chunk 0 to a CSV file...\n",
      "Processing chunk 100 to 200...\n",
      "Saving chunk 100 to a CSV file...\n",
      "Processing chunk 200 to 300...\n",
      "Saving chunk 200 to a CSV file...\n",
      "Processing chunk 300 to 400...\n",
      "Saving chunk 300 to a CSV file...\n",
      "Processing chunk 400 to 500...\n",
      "Saving chunk 400 to a CSV file...\n",
      "Processing chunk 500 to 600...\n",
      "Saving chunk 500 to a CSV file...\n",
      "Processing chunk 600 to 700...\n",
      "Saving chunk 600 to a CSV file...\n",
      "Processing chunk 700 to 800...\n",
      "Saving chunk 700 to a CSV file...\n",
      "Processing chunk 800 to 900...\n",
      "Saving chunk 800 to a CSV file...\n",
      "Processing chunk 900 to 1000...\n",
      "Saving chunk 900 to a CSV file...\n",
      "Processing chunk 1000 to 1100...\n",
      "Saving chunk 1000 to a CSV file...\n",
      "Processing chunk 1100 to 1200...\n",
      "Saving chunk 1100 to a CSV file...\n",
      "Processing chunk 1200 to 1300...\n",
      "Saving chunk 1200 to a CSV file...\n",
      "Processing chunk 1300 to 1400...\n",
      "Saving chunk 1300 to a CSV file...\n",
      "Processing chunk 1400 to 1500...\n",
      "Saving chunk 1400 to a CSV file...\n",
      "Processing chunk 1500 to 1600...\n",
      "Saving chunk 1500 to a CSV file...\n",
      "Processing chunk 1600 to 1700...\n",
      "Saving chunk 1600 to a CSV file...\n",
      "Processing chunk 1700 to 1800...\n",
      "Saving chunk 1700 to a CSV file...\n",
      "Processing chunk 1800 to 1900...\n",
      "Saving chunk 1800 to a CSV file...\n",
      "Processing chunk 1900 to 2000...\n",
      "Saving chunk 1900 to a CSV file...\n",
      "Processing chunk 2000 to 2100...\n",
      "Saving chunk 2000 to a CSV file...\n",
      "Processing chunk 2100 to 2200...\n",
      "Saving chunk 2100 to a CSV file...\n",
      "Processing chunk 2200 to 2300...\n",
      "Saving chunk 2200 to a CSV file...\n",
      "Processing chunk 2300 to 2400...\n",
      "Saving chunk 2300 to a CSV file...\n",
      "Processing chunk 2400 to 2500...\n",
      "Saving chunk 2400 to a CSV file...\n",
      "Processing chunk 2500 to 2600...\n",
      "Saving chunk 2500 to a CSV file...\n",
      "Processing chunk 2600 to 2700...\n",
      "Saving chunk 2600 to a CSV file...\n",
      "Processing chunk 2700 to 2800...\n",
      "Saving chunk 2700 to a CSV file...\n",
      "Processing chunk 2800 to 2900...\n",
      "Saving chunk 2800 to a CSV file...\n",
      "Processing chunk 2900 to 3000...\n",
      "Saving chunk 2900 to a CSV file...\n",
      "Processing chunk 3000 to 3100...\n",
      "Saving chunk 3000 to a CSV file...\n",
      "Processing chunk 3100 to 3200...\n",
      "Saving chunk 3100 to a CSV file...\n",
      "Processing chunk 3200 to 3300...\n",
      "Saving chunk 3200 to a CSV file...\n",
      "Processing chunk 3300 to 3400...\n",
      "Saving chunk 3300 to a CSV file...\n",
      "Processing chunk 3400 to 3500...\n",
      "Saving chunk 3400 to a CSV file...\n",
      "Processing chunk 3500 to 3600...\n",
      "Saving chunk 3500 to a CSV file...\n",
      "Processing chunk 3600 to 3700...\n",
      "Saving chunk 3600 to a CSV file...\n",
      "Processing chunk 3700 to 3800...\n",
      "Saving chunk 3700 to a CSV file...\n",
      "Processing chunk 3800 to 3900...\n",
      "Saving chunk 3800 to a CSV file...\n",
      "Processing chunk 3900 to 4000...\n",
      "Saving chunk 3900 to a CSV file...\n",
      "Processing chunk 4000 to 4100...\n",
      "Saving chunk 4000 to a CSV file...\n",
      "Processing chunk 4100 to 4200...\n",
      "Saving chunk 4100 to a CSV file...\n",
      "Processing chunk 4200 to 4300...\n",
      "Saving chunk 4200 to a CSV file...\n",
      "Processing chunk 4300 to 4400...\n",
      "Saving chunk 4300 to a CSV file...\n",
      "Processing chunk 4400 to 4500...\n",
      "Saving chunk 4400 to a CSV file...\n",
      "Processing chunk 4500 to 4600...\n",
      "Saving chunk 4500 to a CSV file...\n",
      "Processing chunk 4600 to 4700...\n",
      "Saving chunk 4600 to a CSV file...\n",
      "Processing chunk 4700 to 4800...\n",
      "Saving chunk 4700 to a CSV file...\n",
      "Processing chunk 4800 to 4900...\n",
      "Saving chunk 4800 to a CSV file...\n",
      "Processing chunk 4900 to 5000...\n",
      "Saving chunk 4900 to a CSV file...\n",
      "Processing chunk 5000 to 5100...\n",
      "Saving chunk 5000 to a CSV file...\n",
      "Processing chunk 5100 to 5200...\n",
      "Saving chunk 5100 to a CSV file...\n",
      "Processing chunk 5200 to 5300...\n",
      "Saving chunk 5200 to a CSV file...\n",
      "Processing chunk 5300 to 5400...\n",
      "Saving chunk 5300 to a CSV file...\n",
      "Processing chunk 5400 to 5500...\n",
      "Saving chunk 5400 to a CSV file...\n",
      "Processing chunk 5500 to 5600...\n",
      "Saving chunk 5500 to a CSV file...\n",
      "Processing chunk 5600 to 5700...\n",
      "Saving chunk 5600 to a CSV file...\n",
      "Processing chunk 5700 to 5800...\n",
      "Saving chunk 5700 to a CSV file...\n",
      "Processing chunk 5800 to 5900...\n",
      "Saving chunk 5800 to a CSV file...\n",
      "Processing chunk 5900 to 6000...\n",
      "Saving chunk 5900 to a CSV file...\n",
      "Processing chunk 6000 to 6100...\n",
      "Saving chunk 6000 to a CSV file...\n",
      "Processing chunk 6100 to 6200...\n",
      "Saving chunk 6100 to a CSV file...\n",
      "Processing chunk 6200 to 6300...\n",
      "Saving chunk 6200 to a CSV file...\n",
      "Processing chunk 6300 to 6400...\n",
      "Saving chunk 6300 to a CSV file...\n",
      "Processing chunk 6400 to 6500...\n",
      "Saving chunk 6400 to a CSV file...\n",
      "Processing chunk 6500 to 6600...\n",
      "Saving chunk 6500 to a CSV file...\n",
      "Processing chunk 6600 to 6700...\n",
      "Saving chunk 6600 to a CSV file...\n",
      "Processing chunk 6700 to 6800...\n",
      "Saving chunk 6700 to a CSV file...\n",
      "Processing chunk 6800 to 6900...\n",
      "Saving chunk 6800 to a CSV file...\n",
      "Processing chunk 6900 to 7000...\n",
      "Saving chunk 6900 to a CSV file...\n",
      "Processing chunk 7000 to 7100...\n",
      "Saving chunk 7000 to a CSV file...\n",
      "Processing chunk 7100 to 7200...\n",
      "Saving chunk 7100 to a CSV file...\n",
      "Processing chunk 7200 to 7300...\n",
      "Saving chunk 7200 to a CSV file...\n",
      "Processing chunk 7300 to 7400...\n",
      "Saving chunk 7300 to a CSV file...\n",
      "Processing chunk 7400 to 7500...\n",
      "Saving chunk 7400 to a CSV file...\n",
      "Processing chunk 7500 to 7600...\n",
      "Saving chunk 7500 to a CSV file...\n",
      "Processing chunk 7600 to 7700...\n",
      "Saving chunk 7600 to a CSV file...\n",
      "Processing chunk 7700 to 7800...\n",
      "Saving chunk 7700 to a CSV file...\n",
      "Processing chunk 7800 to 7900...\n",
      "Saving chunk 7800 to a CSV file...\n",
      "Processing chunk 7900 to 8000...\n",
      "Saving chunk 7900 to a CSV file...\n",
      "Processing chunk 8000 to 8100...\n",
      "Saving chunk 8000 to a CSV file...\n",
      "Processing chunk 8100 to 8200...\n",
      "Saving chunk 8100 to a CSV file...\n",
      "Processing chunk 8200 to 8300...\n",
      "Saving chunk 8200 to a CSV file...\n",
      "Processing chunk 8300 to 8400...\n",
      "Saving chunk 8300 to a CSV file...\n",
      "Processing chunk 8400 to 8500...\n",
      "Saving chunk 8400 to a CSV file...\n"
     ]
    }
   ],
   "source": [
    "feature_csv(\"user_features.csv\", \"Top Tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating...\n",
      "finished concatenating\n"
     ]
    }
   ],
   "source": [
    "top_tracks_df = concatenate_feature_csvs(\"Top Tracks\")\n",
    "top_tracks_df = top_tracks_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43186"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_tracks_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating...\n",
      "finished concatenating\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "top_artists_df = concatenate_feature_csvs(\"Top Artists\")\n",
    "print(1)\n",
    "top_artists_df = top_artists_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17729"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_artists_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating...\n",
      "finished concatenating\n"
     ]
    }
   ],
   "source": [
    "top_tags_df = concatenate_feature_csvs(\"Top Tags\")\n",
    "top_tags_df = top_tags_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_tags_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top_tracks_distance(username, top_tracks_df):\n",
    "    # get user features\n",
    "    last_fm = lastfm_api('/Users/ziandong/TreeMusicRecommendation/Data/conf.json')\n",
    "    user_feature = last_fm.get_user_features(username)\n",
    "    user_feature['top_tracks'] = calculate_top_tracks_score(user_feature['top_tracks'])\n",
    "\n",
    "    # convert user features to vector\n",
    "    # top track vector\n",
    "    top_track_ids = top_tracks_df.columns[top_tracks_df.columns != \"user_id\"]\n",
    "    top_tracks_map = {track_id: idx for idx, track_id in enumerate(top_track_ids)}\n",
    "    user_top_tracks = np.zeros(len(top_track_ids))\n",
    "    for track_id  in user_feature['top_tracks']:\n",
    "        if track_id in top_tracks_map:\n",
    "            user_top_tracks[top_tracks_map[track_id]] = user_feature['top_tracks'][track_id]\n",
    "\n",
    "    # convert database user features to model input arrays\n",
    "    top_tracks = top_tracks_df.drop(columns=['user_id']).values\n",
    "\n",
    "    # calculate distance\n",
    "    top_tracks_distances = distance.cdist([user_top_tracks], top_tracks, 'euclidean').flatten() / np.sqrt(len(user_top_tracks))\n",
    "\n",
    "    # map each distance to a user id\n",
    "    top_tracks_distances_df = pd.DataFrame(top_tracks_distances, columns=['top_tracks_distance'])\n",
    "    top_tracks_distances_df['user_id'] = top_tracks_df['user_id']\n",
    "    \n",
    "    return top_tracks_distances_df\n",
    "\n",
    "\n",
    "def calculate_top_artists_distance(username, top_artists_df):\n",
    "    # get user features\n",
    "    last_fm = lastfm_api('/Users/ziandong/TreeMusicRecommendation/Data/conf.json')\n",
    "    user_feature = last_fm.get_user_features(username)\n",
    "    user_feature['top_artists'] = calculate_top_artists_score(user_feature['top_artists'])\n",
    "\n",
    "    # convert user features to vector\n",
    "    # top artist vector\n",
    "    top_artist_ids = top_artists_df.columns[top_artists_df.columns != \"user_id\"]\n",
    "    top_artists_map = {artist_id: idx for idx, artist_id in enumerate(top_artist_ids)}\n",
    "    user_top_artists = np.zeros(len(top_artist_ids))\n",
    "    for artist_id  in user_feature['top_artists']:\n",
    "        if artist_id in top_artists_map:\n",
    "            user_top_artists[top_artists_map[artist_id]] = user_feature['top_artists'][artist_id]\n",
    "    \n",
    "    # convert database user features to model input arrays\n",
    "    top_artists = top_artists_df.drop(columns=['user_id']).values\n",
    "\n",
    "    # calculate distance\n",
    "    top_artists_distances = distance.cdist([user_top_artists], top_artists, 'euclidean').flatten() / np.sqrt(len(user_top_artists))\n",
    "\n",
    "    # map each distance to a user id\n",
    "    top_artists_distances_df = pd.DataFrame(top_artists_distances, columns=['top_artists_distance'])\n",
    "    top_artists_distances_df['user_id'] = top_artists_df['user_id']\n",
    "\n",
    "    return top_artists_distances_df\n",
    "\n",
    "\n",
    "def calculate_top_tags_distance(username, top_tags_df):\n",
    "    # get user features\n",
    "    last_fm = lastfm_api('/Users/ziandong/TreeMusicRecommendation/Data/conf.json')\n",
    "    user_feature = last_fm.get_user_features(username)\n",
    "    user_tags = fetch_user_tag(urls_to_text(list(user_feature['top_artists'].keys())[0:10]))\n",
    "    user_tags = user_tags.split(', ')\n",
    "    user_feature['top_tags'] = {tag.split(\": \")[0].replace('\"', ''): float(tag.split(\": \")[1].replace('\"', '')) for tag in user_tags}\n",
    "\n",
    "    # convert user features to vector\n",
    "    # top tag vector\n",
    "    top_tag_ids = top_tags_df.columns[top_tags_df.columns != \"user_id\"]\n",
    "    top_tags_map = {tag: idx for idx, tag in enumerate(top_tag_ids)}\n",
    "    user_top_tags = np.zeros(len(top_tag_ids))\n",
    "    for tag  in user_feature['top_tags']:\n",
    "        if tag in top_tags_map:\n",
    "            user_top_tags[top_tags_map[tag]] = user_feature['top_tags'][tag]\n",
    "\n",
    "    # convert database user features to model input arrays\n",
    "    top_tags = top_tags_df.drop(columns=['user_id']).values\n",
    "\n",
    "    # calculate distance\n",
    "    top_tags_distances = distance.cdist([user_top_tags], top_tags, 'euclidean').flatten() / np.sqrt(len(user_top_tags))\n",
    "\n",
    "    # map each distance to a user id\n",
    "    top_tags_distances_df = pd.DataFrame(top_tags_distances, columns=['top_tags_distance'])\n",
    "    top_tags_distances_df['user_id'] = top_tags_df['user_id']\n",
    "\n",
    "    return top_tags_distances_df\n",
    "\n",
    "\n",
    "def calculate_user_distance(username, top_tracks_df, top_artists_df, top_tags_df):\n",
    "    database = database_api('/Users/ziandong/TreeMusicRecommendation/Data/conf.json')\n",
    "\n",
    "    top_tags_distances_df = calculate_top_tags_distance(username, top_tags_df)\n",
    "    print(\"finish top tags\")\n",
    "    top_tracks_distances_df = calculate_top_tracks_distance(username, top_tracks_df)\n",
    "    print(\"finish top tracks\")\n",
    "    top_artists_distances_df = calculate_top_artists_distance(username, top_artists_df)\n",
    "    print(\"finish top artists\")\n",
    "\n",
    "    # merge all distances\n",
    "    distances_df = top_tracks_distances_df.merge(top_artists_distances_df, on='user_id')\n",
    "    distances_df = distances_df.merge(top_tags_distances_df, on='user_id')\n",
    "    print(\"finish merge\")\n",
    "\n",
    "    # calculate total distance\n",
    "    distances_df['distance'] = distances_df['top_tags_distance'] + distances_df['top_artists_distance'] + distances_df['top_tracks_distance']\n",
    "    print(\"finish calculate distance\")\n",
    "\n",
    "    # calculate similarity score\n",
    "    distances_df['similarity_score'] = 1 / (1 + 10 * distances_df['distance']) * 100\n",
    "    print(\"finish calculate similarity score\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # sort by distance\n",
    "    distances_df = distances_df.sort_values(by=['distance'])\n",
    "    print(\"finish sort\")\n",
    "\n",
    "    # fetch the first 10 users\n",
    "    distances_df = distances_df.head(10)\n",
    "    print(\"finish fetch\")\n",
    "\n",
    "    # apply normalization to map it into (10,40)\n",
    "    distances_df['similarity_score'] = distances_df['similarity_score'].apply(lambda x: 20 + 20 * (x - distances_df['similarity_score'].min()) / (distances_df['similarity_score'].max() - distances_df['similarity_score'].min()))\n",
    "    print(\"finish normalization\")   \n",
    "\n",
    "\n",
    "    distances_df['username'] = distances_df['user_id'].apply(lambda x: database.get_user_name(x))\n",
    "    print(\"finish get username\")\n",
    "\n",
    "    return distances_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select non na columns\n",
    "test = calculate_top_tracks_distance('Thiagotake', top_tracks_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = calculate_top_artists_distance('Thiagotake', top_artists_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = calculate_top_tags_distance('Thiagotake', top_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish top tags\n",
      "finish top tracks\n",
      "finish top artists\n",
      "finish merge\n",
      "finish calculate distance\n",
      "finish calculate similarity score\n",
      "finish sort\n",
      "finish fetch\n",
      "finish normalization\n",
      "finish get username\n"
     ]
    }
   ],
   "source": [
    "test = calculate_user_distance('Thiagotake', top_tracks_df, top_artists_df, top_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_tracks_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>top_artists_distance</th>\n",
       "      <th>top_tags_distance</th>\n",
       "      <th>distance</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>0.005418</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>Thiagotake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>0.011579</td>\n",
       "      <td>6729</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026409</td>\n",
       "      <td>25.575614</td>\n",
       "      <td>whodulvato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>0.010663</td>\n",
       "      <td>6822</td>\n",
       "      <td>0.017579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>23.920995</td>\n",
       "      <td>lucaslimaq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8176</th>\n",
       "      <td>0.010749</td>\n",
       "      <td>829</td>\n",
       "      <td>0.017702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>23.735917</td>\n",
       "      <td>robertoferrer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>0.012504</td>\n",
       "      <td>3285</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029263</td>\n",
       "      <td>23.021142</td>\n",
       "      <td>HotDougie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>0.012165</td>\n",
       "      <td>7767</td>\n",
       "      <td>0.017184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>22.945148</td>\n",
       "      <td>jonalbuquerque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>0.011886</td>\n",
       "      <td>8337</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>22.845899</td>\n",
       "      <td>cossmicc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>0.012353</td>\n",
       "      <td>6540</td>\n",
       "      <td>0.017632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029985</td>\n",
       "      <td>22.392199</td>\n",
       "      <td>xVenus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>0.013377</td>\n",
       "      <td>6524</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>20.251547</td>\n",
       "      <td>Vitor_Sarmento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>0.014801</td>\n",
       "      <td>2206</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032808</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>shaxmx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      top_tracks_distance  user_id  top_artists_distance  top_tags_distance  \\\n",
       "3455             0.005418        3              0.006981                0.0   \n",
       "6124             0.011579     6729              0.014831                0.0   \n",
       "7705             0.010663     6822              0.017579                0.0   \n",
       "8176             0.010749      829              0.017702                0.0   \n",
       "4763             0.012504     3285              0.016758                0.0   \n",
       "2895             0.012165     7767              0.017184                0.0   \n",
       "5144             0.011886     8337              0.017577                0.0   \n",
       "7865             0.012353     6540              0.017632                0.0   \n",
       "5351             0.013377     6524              0.019129                0.0   \n",
       "3073             0.014801     2206              0.018007                0.0   \n",
       "\n",
       "      distance  similarity_score        username  \n",
       "3455  0.012399         40.000000      Thiagotake  \n",
       "6124  0.026409         25.575614      whodulvato  \n",
       "7705  0.028243         23.920995      lucaslimaq  \n",
       "8176  0.028451         23.735917   robertoferrer  \n",
       "4763  0.029263         23.021142       HotDougie  \n",
       "2895  0.029349         22.945148  jonalbuquerque  \n",
       "5144  0.029463         22.845899        cossmicc  \n",
       "7865  0.029985         22.392199          xVenus  \n",
       "5351  0.032505         20.251547  Vitor_Sarmento  \n",
       "3073  0.032808         20.000000          shaxmx  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
